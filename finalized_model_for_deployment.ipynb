{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as rsq\n",
    "import xgboost as xgb\n",
    "from feature_engine.categorical_encoders import OrdinalCategoricalEncoder\n",
    "from feature_engine.categorical_encoders import CountFrequencyCategoricalEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data(this data set not conataing null becoz we have imputed null vallues using cluster imputation)\n",
    "data=pd.read_csv(r\"C:\\Users\\sak\\Desktop\\excelr_proj_1\\data_no_null.csv\",encoding='latin1')# reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns not necessary for prediction\n",
    "cols_to_drop=['Unnamed: 0','sub_grade','State','Emp_designation','last_week_pay']\n",
    "# dropping the unnecessary columns\n",
    "df_xg=data.drop(columns=cols_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['terms',\n",
       " 'grade',\n",
       " 'home_ownership',\n",
       " 'verification_status',\n",
       " 'purpose',\n",
       " 'initial_list_status',\n",
       " 'application_type',\n",
       " 'Experience']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = [col for col in df_xg.columns if df_xg[col].dtypes == 'O']\n",
    "\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xg[['purpose']] = df_xg[['purpose']].replace(['car','house','renewable_energy','wedding','vacation','moving','medical','educational'],\n",
    "                                              ['major_purchase','major_purchase','small_business','other','other','other','medical(or)education','medical(or)education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medical(or)education      8963\n",
       "small_business           10952\n",
       "major_purchase           29847\n",
       "home_improvement         51829\n",
       "other                    55391\n",
       "credit_card             206182\n",
       "debt_consolidation      524215\n",
       "Name: purpose, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg.purpose.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_enc = CountFrequencyCategoricalEncoder(\n",
    "    encoding_method='frequency',\n",
    "    variables=categorical)\n",
    "\n",
    "df_xg_fre_enc = ordinal_enc.fit_transform(df_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xg_f=df_xg_fre_enc[['loan_amnt ', 'terms', 'Rate_of_intrst', 'grade', 'home_ownership',\n",
    "       'annual_inc', 'verification_status', 'purpose', 'debt_income_ratio',\n",
    "       'delinq_2yrs', 'inq_last_6mths', 'numb_credit', 'pub_rec',\n",
    "       'total_credits', 'initial_list_status',\n",
    "       'total_rec_int', 'total_rec_late_fee', 'recoveries',\n",
    "       'collection_recovery_fee', 'collections_12_mths_ex_med',\n",
    "       'application_type', 'acc_now_delinq', 'Experience',\n",
    "       'mths_since_last_delinq', 'tot_curr_bal', 'tot_colle_amt']]\n",
    "Y_xg_f=df_xg_fre_enc[['total revol_bal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((709903, 26), (177476, 26))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train_xg_f, X_test_xg_f, y_train_xg_f, y_test_xg_f = train_test_split(X_xg_f  ,  # predictors\n",
    "                                                    Y_xg_f,  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=2)  # seed to ensure reproducibility\n",
    "\n",
    "X_train_xg_f.shape, X_test_xg_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed: 102.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_child_weight': 5, 'max_depth': 8, 'learning_rate': 0.05, 'gamma': 0.2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mod_f=xgb.XGBRegressor()\n",
    "params_f={\n",
    "        'learning_rate':[0.03,0.05,0.08,0.10,0.15,0.20,0.25,0.30],\n",
    "        'max_depth':[3,4,5,6,8,10,12,15,20,25],\n",
    "        'min_child_weight':[1,3,5,7],\n",
    "        'gamma':[0.0,0.1,0.2,0.3,0.4]\n",
    "        }\n",
    "random_search_f=RandomizedSearchCV(xgb_mod_f,param_distributions=params_f,n_iter=5,n_jobs=-1,cv=5,verbose=3)\n",
    "random_search_f.fit(X_train_xg_f,y_train_xg_f)\n",
    "random_search_f.best_estimator_\n",
    "random_search_f.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0.2, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.05, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mod_f=xgb.XGBRegressor(min_child_weight=5, max_depth=8, learning_rate=0.05, gamma=0.2)\n",
    "xgb_mod_f.fit(X_train_xg_f,y_train_xg_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5089314238210529"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_pred_train_f=xgb_mod_f.predict(X_train_xg_f) \n",
    "xg_train_f_r2=rsq(y_train_xg_f,xg_pred_train_f)            \n",
    "xg_train_f_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4407332400064612"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_pred_test_f=xgb_mod_f.predict(X_test_xg_f)\n",
    "xg_test_f_r2=rsq(y_test_xg_f,xg_pred_test_f)\n",
    "xg_test_f_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R^2 : 0.5089314238210529\n",
      "test R^2 : 0.4407332400064612\n"
     ]
    }
   ],
   "source": [
    "print(\"train R^2 :\", xg_train_f_r2)\n",
    "print(\"test R^2 :\", xg_test_f_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train RMSE : 15658.09008543791\n",
      " test RMSE : 17016.016089631652\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(' train RMSE :', np.sqrt(metrics.mean_squared_error(y_train_xg_f,xg_pred_train_f)))\n",
    "print(' test RMSE :', np.sqrt(metrics.mean_squared_error(y_test_xg_f,xg_pred_test_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>feature importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loan_amnt</td>\n",
       "      <td>0.203547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terms</td>\n",
       "      <td>0.018773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rate_of_intrst</td>\n",
       "      <td>0.019602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grade</td>\n",
       "      <td>0.052965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>home_ownership</td>\n",
       "      <td>0.031748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>0.070570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>verification_status</td>\n",
       "      <td>0.028143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>purpose</td>\n",
       "      <td>0.024774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>debt_income_ratio</td>\n",
       "      <td>0.061961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>delinq_2yrs</td>\n",
       "      <td>0.016206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inq_last_6mths</td>\n",
       "      <td>0.026130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>numb_credit</td>\n",
       "      <td>0.041782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pub_rec</td>\n",
       "      <td>0.036153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_credits</td>\n",
       "      <td>0.035607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>initial_list_status</td>\n",
       "      <td>0.023499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_rec_int</td>\n",
       "      <td>0.022242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>total_rec_late_fee</td>\n",
       "      <td>0.011020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recoveries</td>\n",
       "      <td>0.018283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>collection_recovery_fee</td>\n",
       "      <td>0.003702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>collections_12_mths_ex_med</td>\n",
       "      <td>0.003752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>application_type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>acc_now_delinq</td>\n",
       "      <td>0.005161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Experience</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mths_since_last_delinq</td>\n",
       "      <td>0.034597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tot_curr_bal</td>\n",
       "      <td>0.159240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tot_colle_amt</td>\n",
       "      <td>0.019629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       columns  feature importance\n",
       "0                   loan_amnt             0.203547\n",
       "1                        terms            0.018773\n",
       "2               Rate_of_intrst            0.019602\n",
       "3                        grade            0.052965\n",
       "4               home_ownership            0.031748\n",
       "5                   annual_inc            0.070570\n",
       "6          verification_status            0.028143\n",
       "7                      purpose            0.024774\n",
       "8            debt_income_ratio            0.061961\n",
       "9                  delinq_2yrs            0.016206\n",
       "10              inq_last_6mths            0.026130\n",
       "11                 numb_credit            0.041782\n",
       "12                     pub_rec            0.036153\n",
       "13               total_credits            0.035607\n",
       "14         initial_list_status            0.023499\n",
       "15               total_rec_int            0.022242\n",
       "16          total_rec_late_fee            0.011020\n",
       "17                  recoveries            0.018283\n",
       "18     collection_recovery_fee            0.003702\n",
       "19  collections_12_mths_ex_med            0.003752\n",
       "20            application_type            0.000000\n",
       "21              acc_now_delinq            0.005161\n",
       "22                  Experience            0.030914\n",
       "23      mths_since_last_delinq            0.034597\n",
       "24                tot_curr_bal            0.159240\n",
       "25               tot_colle_amt            0.019629"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_xg_f=list(xgb_mod_f.feature_importances_)\n",
    "j_xg_f=list(X_train_xg_f.columns)\n",
    "data_xg_f ={'columns': j_xg_f, 'feature importance':k_xg_f}\n",
    "d_xg_f=pd.DataFrame(data_xg_f)\n",
    "d_xg_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### so here i m droping the features whose importance is less than 1% :-\n",
    "collection_recovery_fee\n",
    "\n",
    "collections_12_mths_ex_med\n",
    "\n",
    "application_type\n",
    "\n",
    "acc_now_delinq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xg_f_1=df_xg_fre_enc[['loan_amnt ', 'terms', 'Rate_of_intrst', 'grade', 'home_ownership','annual_inc', 'verification_status',\n",
    "                        'purpose', 'debt_income_ratio','delinq_2yrs', 'inq_last_6mths', 'numb_credit', 'pub_rec', 'total_credits', \n",
    "                        'initial_list_status','total_rec_int', 'total_rec_late_fee', 'recoveries','Experience','mths_since_last_delinq', \n",
    "                        'tot_curr_bal', 'tot_colle_amt']]\n",
    "Y_xg_f_1=df_xg_fre_enc[['total revol_bal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((709903, 22), (177476, 22))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing set\n",
    "\n",
    "X_train_xg_f_1, X_test_xg_f_1, y_train_xg_f_1, y_test_xg_f_1 = train_test_split(X_xg_f_1  ,  # predictors\n",
    "                                                    Y_xg_f_1,  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=2)  # seed to ensure reproducibility\n",
    "\n",
    "X_train_xg_f_1.shape, X_test_xg_f_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0.2, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.05, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mod_f_1=xgb.XGBRegressor(min_child_weight=5, max_depth=8, learning_rate=0.05, gamma=0.2)\n",
    "xgb_mod_f_1.fit(np.array(X_train_xg_f_1),np.array(y_train_xg_f_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_pred_train_f_1=xgb_mod_f_1.predict(np.array(X_train_xg_f_1)) \n",
    "xg_train_f_1_r2=rsq(y_train_xg_f_1,xg_pred_train_f_1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_pred_test_f_1=xgb_mod_f_1.predict(np.array(X_test_xg_f_1)) \n",
    "xg_test_f_1_r2=rsq(y_test_xg_f_1,xg_pred_test_f_1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R^2 : 0.5097571950185633\n",
      "test R^2 : 0.44068751147380736\n"
     ]
    }
   ],
   "source": [
    "print(\"train R^2 :\", xg_train_f_1_r2)\n",
    "print(\"test R^2 :\", xg_test_f_1_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train RMSE : 15644.919379032443\n",
      " test RMSE : 17016.71173399851\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(' train RMSE :', np.sqrt(metrics.mean_squared_error(y_train_xg_f_1,xg_pred_train_f_1)))\n",
    "print(' test RMSE :', np.sqrt(metrics.mean_squared_error(y_test_xg_f_1,xg_pred_test_f_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>feature importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loan_amnt</td>\n",
       "      <td>0.207254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terms</td>\n",
       "      <td>0.015490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rate_of_intrst</td>\n",
       "      <td>0.020452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grade</td>\n",
       "      <td>0.062843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>home_ownership</td>\n",
       "      <td>0.032113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>0.073571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>verification_status</td>\n",
       "      <td>0.029132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>purpose</td>\n",
       "      <td>0.023839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>debt_income_ratio</td>\n",
       "      <td>0.062091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>delinq_2yrs</td>\n",
       "      <td>0.015066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inq_last_6mths</td>\n",
       "      <td>0.025322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>numb_credit</td>\n",
       "      <td>0.039623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pub_rec</td>\n",
       "      <td>0.035315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_credits</td>\n",
       "      <td>0.035080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>initial_list_status</td>\n",
       "      <td>0.028807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_rec_int</td>\n",
       "      <td>0.021983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>total_rec_late_fee</td>\n",
       "      <td>0.010782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recoveries</td>\n",
       "      <td>0.016116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Experience</td>\n",
       "      <td>0.029544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mths_since_last_delinq</td>\n",
       "      <td>0.034391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tot_curr_bal</td>\n",
       "      <td>0.160724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tot_colle_amt</td>\n",
       "      <td>0.020461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   columns  feature importance\n",
       "0               loan_amnt             0.207254\n",
       "1                    terms            0.015490\n",
       "2           Rate_of_intrst            0.020452\n",
       "3                    grade            0.062843\n",
       "4           home_ownership            0.032113\n",
       "5               annual_inc            0.073571\n",
       "6      verification_status            0.029132\n",
       "7                  purpose            0.023839\n",
       "8        debt_income_ratio            0.062091\n",
       "9              delinq_2yrs            0.015066\n",
       "10          inq_last_6mths            0.025322\n",
       "11             numb_credit            0.039623\n",
       "12                 pub_rec            0.035315\n",
       "13           total_credits            0.035080\n",
       "14     initial_list_status            0.028807\n",
       "15           total_rec_int            0.021983\n",
       "16      total_rec_late_fee            0.010782\n",
       "17              recoveries            0.016116\n",
       "18              Experience            0.029544\n",
       "19  mths_since_last_delinq            0.034391\n",
       "20            tot_curr_bal            0.160724\n",
       "21           tot_colle_amt            0.020461"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_xg_f_1=list(xgb_mod_f_1.feature_importances_)\n",
    "j_xg_f_1=list(X_train_xg_f_1.columns)\n",
    "data_xg_f_1 ={'columns': j_xg_f_1, 'feature importance':k_xg_f_1}\n",
    "d_xg_f_1=pd.DataFrame(data_xg_f_1)\n",
    "d_xg_f_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(xgb_mod_f_1,open('finalized_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>terms</th>\n",
       "      <th>Rate_of_intrst</th>\n",
       "      <th>grade</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>debt_income_ratio</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>total_credits</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>Experience</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>tot_curr_bal</th>\n",
       "      <th>tot_colle_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257329</th>\n",
       "      <td>21000</td>\n",
       "      <td>0.699955</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0.286839</td>\n",
       "      <td>0.499851</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>0.232349</td>\n",
       "      <td>15.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.485171</td>\n",
       "      <td>500.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>368784.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578111</th>\n",
       "      <td>10800</td>\n",
       "      <td>0.699955</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.286839</td>\n",
       "      <td>0.499851</td>\n",
       "      <td>86000.0</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>0.232349</td>\n",
       "      <td>14.04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.514829</td>\n",
       "      <td>932.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088880</td>\n",
       "      <td>11.0</td>\n",
       "      <td>77079.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9432</th>\n",
       "      <td>17450</td>\n",
       "      <td>0.300045</td>\n",
       "      <td>14.48</td>\n",
       "      <td>0.277063</td>\n",
       "      <td>0.098571</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>0.232349</td>\n",
       "      <td>31.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.485171</td>\n",
       "      <td>196.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078913</td>\n",
       "      <td>29.0</td>\n",
       "      <td>428523.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194402</th>\n",
       "      <td>15450</td>\n",
       "      <td>0.699955</td>\n",
       "      <td>14.98</td>\n",
       "      <td>0.277063</td>\n",
       "      <td>0.401313</td>\n",
       "      <td>46000.0</td>\n",
       "      <td>0.328012</td>\n",
       "      <td>0.590745</td>\n",
       "      <td>30.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.485171</td>\n",
       "      <td>3253.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379087</td>\n",
       "      <td>32.0</td>\n",
       "      <td>47212.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23248</th>\n",
       "      <td>3500</td>\n",
       "      <td>0.699955</td>\n",
       "      <td>9.49</td>\n",
       "      <td>0.286839</td>\n",
       "      <td>0.098571</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>0.371384</td>\n",
       "      <td>0.058407</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.514829</td>\n",
       "      <td>285.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379087</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24026.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803673</th>\n",
       "      <td>18000</td>\n",
       "      <td>0.300045</td>\n",
       "      <td>14.65</td>\n",
       "      <td>0.277063</td>\n",
       "      <td>0.499851</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.371384</td>\n",
       "      <td>0.058407</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.485171</td>\n",
       "      <td>1469.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379087</td>\n",
       "      <td>29.0</td>\n",
       "      <td>292792.0</td>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114262</th>\n",
       "      <td>9450</td>\n",
       "      <td>0.699955</td>\n",
       "      <td>7.62</td>\n",
       "      <td>0.167011</td>\n",
       "      <td>0.401313</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>10.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.485171</td>\n",
       "      <td>531.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062774</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29247.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570827</th>\n",
       "      <td>11200</td>\n",
       "      <td>0.699955</td>\n",
       "      <td>5.32</td>\n",
       "      <td>0.167011</td>\n",
       "      <td>0.401313</td>\n",
       "      <td>80028.0</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>0.590745</td>\n",
       "      <td>17.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.485171</td>\n",
       "      <td>138.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059196</td>\n",
       "      <td>34.0</td>\n",
       "      <td>71126.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18160</th>\n",
       "      <td>25000</td>\n",
       "      <td>0.699955</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.277063</td>\n",
       "      <td>0.499851</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.371384</td>\n",
       "      <td>0.590745</td>\n",
       "      <td>12.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.514829</td>\n",
       "      <td>3473.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049534</td>\n",
       "      <td>29.0</td>\n",
       "      <td>293885.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269407</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.699955</td>\n",
       "      <td>13.11</td>\n",
       "      <td>0.286839</td>\n",
       "      <td>0.401313</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>0.590745</td>\n",
       "      <td>23.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.514829</td>\n",
       "      <td>865.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079566</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14243.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177476 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loan_amnt      terms  Rate_of_intrst     grade  home_ownership  \\\n",
       "257329       21000  0.699955            9.99  0.286839        0.499851   \n",
       "578111       10800  0.699955           14.09  0.286839        0.499851   \n",
       "9432         17450  0.300045           14.48  0.277063        0.098571   \n",
       "194402       15450  0.699955           14.98  0.277063        0.401313   \n",
       "23248         3500  0.699955            9.49  0.286839        0.098571   \n",
       "...            ...       ...             ...       ...             ...   \n",
       "803673       18000  0.300045           14.65  0.277063        0.499851   \n",
       "114262        9450  0.699955            7.62  0.167011        0.401313   \n",
       "570827       11200  0.699955            5.32  0.167011        0.401313   \n",
       "18160        25000  0.699955           14.99  0.277063        0.499851   \n",
       "269407        5000  0.699955           13.11  0.286839        0.401313   \n",
       "\n",
       "        annual_inc  verification_status   purpose  debt_income_ratio  \\\n",
       "257329    110000.0             0.300604  0.232349              15.51   \n",
       "578111     86000.0             0.300604  0.232349              14.04   \n",
       "9432       82000.0             0.300604  0.232349              31.90   \n",
       "194402     46000.0             0.328012  0.590745              30.01   \n",
       "23248      65000.0             0.371384  0.058407               3.80   \n",
       "...            ...                  ...       ...                ...   \n",
       "803673     70000.0             0.371384  0.058407               5.47   \n",
       "114262     95000.0             0.300604  0.033635              10.02   \n",
       "570827     80028.0             0.300604  0.590745              17.24   \n",
       "18160     120000.0             0.371384  0.590745              12.09   \n",
       "269407     38000.0             0.300604  0.590745              23.05   \n",
       "\n",
       "        delinq_2yrs  ...  pub_rec  total_credits  initial_list_status  \\\n",
       "257329          1.0  ...      0.0           29.0             0.485171   \n",
       "578111          2.0  ...      0.0           36.0             0.514829   \n",
       "9432            0.0  ...      0.0           20.0             0.485171   \n",
       "194402          0.0  ...      0.0           15.0             0.485171   \n",
       "23248           1.0  ...      0.0           17.0             0.514829   \n",
       "...             ...  ...      ...            ...                  ...   \n",
       "803673          0.0  ...      0.0           17.0             0.485171   \n",
       "114262          0.0  ...      0.0           12.0             0.485171   \n",
       "570827          0.0  ...      0.0           27.0             0.485171   \n",
       "18160           0.0  ...      0.0           12.0             0.514829   \n",
       "269407          0.0  ...      0.0           29.0             0.514829   \n",
       "\n",
       "        total_rec_int  total_rec_late_fee  recoveries  Experience  \\\n",
       "257329         500.23                 0.0         0.0    0.088880   \n",
       "578111         932.37                 0.0         0.0    0.088880   \n",
       "9432           196.52                 0.0         0.0    0.078913   \n",
       "194402        3253.31                 0.0         0.0    0.379087   \n",
       "23248          285.05                 0.0         0.0    0.379087   \n",
       "...               ...                 ...         ...         ...   \n",
       "803673        1469.92                 0.0         0.0    0.379087   \n",
       "114262         531.93                 0.0         0.0    0.062774   \n",
       "570827         138.51                 0.0         0.0    0.059196   \n",
       "18160         3473.44                 0.0         0.0    0.049534   \n",
       "269407         865.17                 0.0         0.0    0.079566   \n",
       "\n",
       "        mths_since_last_delinq  tot_curr_bal  tot_colle_amt  \n",
       "257329                     0.0      368784.0            0.0  \n",
       "578111                    11.0       77079.0            0.0  \n",
       "9432                      29.0      428523.0            0.0  \n",
       "194402                    32.0       47212.0            0.0  \n",
       "23248                     15.0       24026.0            0.0  \n",
       "...                        ...           ...            ...  \n",
       "803673                    29.0      292792.0          271.0  \n",
       "114262                    33.0       29247.0            0.0  \n",
       "570827                    34.0       71126.0            0.0  \n",
       "18160                     29.0      293885.0          180.0  \n",
       "269407                    31.0       14243.0            0.0  \n",
       "\n",
       "[177476 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_xg_f_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26938.912 14731.535 52672.99  ... 14104.868 21255.639  8604.716]\n"
     ]
    }
   ],
   "source": [
    "# prediction using the saved model.\n",
    "loaded_model = pickle.load(open('finalized_model.pkl', 'rb'))\n",
    "prediction=loaded_model.predict(np.array(X_test_xg_f_1))\n",
    "\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### so above one is showing our saved model is working fine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"terms\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['terms'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['terms']].values\n",
    "temp_values = a.fit_transform(df_xg[['terms']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['terms'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"terms.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'terms': {'36 months': 0.699954585357553, '60 months': 0.30004541464244705}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"terms.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"grade\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['grade'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['grade']].values\n",
    "temp_values = b.fit_transform(df_xg[['grade']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['grade'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"grade.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'grade': {'E': 0.07967846883913186, 'B': 0.2868391070782608, 'A': 0.16701093895618446, 'D': 0.15725186194399463, 'C': 0.27706312635300134, 'F': 0.025970864760153214, 'G': 0.00618563206927367}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"grade.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"home_ownership\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['home_ownership'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['home_ownership']].values\n",
    "temp_values = c.fit_transform(df_xg[['home_ownership']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['home_ownership'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"home_ownership.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'home_ownership': {'OWN': 0.09857118547993586, 'MORTGAGE': 0.49985068386788506, 'RENT': 0.4013133058140885, 'OTHER': 0.00020509838524463618, 'NONE': 5.6345710232042906e-05, 'ANY': 3.3807426139225743e-06}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"home_ownership.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANY              3\n",
       "MORTGAGE    443557\n",
       "NONE            50\n",
       "OTHER          182\n",
       "OWN          87470\n",
       "RENT        356117\n",
       "Name: home_ownership, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg.home_ownership.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"verification_status\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['verification_status'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['verification_status']].values\n",
    "temp_values = d.fit_transform(df_xg[['verification_status']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['verification_status'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"verification_status.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verification_status': {'Source Verified': 0.3713835914530319, 'Not Verified': 0.3006043640879489, 'Verified': 0.3280120444590192}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"verification_status.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Verified       266750\n",
       "Source Verified    329558\n",
       "Verified           291071\n",
       "Name: verification_status, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg.verification_status.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"purpose\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['purpose'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['purpose']].values\n",
    "temp_values = e.fit_transform(df_xg[['purpose']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['purpose'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"purpose.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'purpose': {'debt_consolidation': 0.5907453297858074, 'home_improvement': 0.05840683631233103, 'credit_card': 0.2323494245412614, 'other': 0.06242090470926177, 'major_purchase': 0.03363500826591569, 'small_business': 0.012341964369226677, 'medical(or)education': 0.01010053201619601}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"purpose.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_card             206182\n",
       "debt_consolidation      524215\n",
       "home_improvement         51829\n",
       "major_purchase           29847\n",
       "medical(or)education      8963\n",
       "other                    55391\n",
       "small_business           10952\n",
       "Name: purpose, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg.purpose.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"initial_list_status\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['initial_list_status'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['initial_list_status']].values\n",
    "temp_values = f.fit_transform(df_xg[['initial_list_status']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['initial_list_status'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"initial_list_status.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initial_list_status': {'f': 0.5148285005617668, 'w': 0.4851714994382333}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"initial_list_status.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    456848\n",
       "w    430531\n",
       "Name: initial_list_status, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg.initial_list_status.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving frequency-encoding of \"Experience\" to disk ----- later used in the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = CountFrequencyCategoricalEncoder(encoding_method='frequency',variables=['Experience'])\n",
    "dict_all = dict(zip([], []))\n",
    "temp_keys = df_xg[['Experience']].values\n",
    "temp_values = g.fit_transform(df_xg[['Experience']])\n",
    "dict_temp = dict(zip(np.array(temp_keys).ravel(),np.array(temp_values).ravel()))\n",
    "dict_all['Experience'] = dict_temp\n",
    "import pickle\n",
    "filehandler = open(\"Experience.obj\",\"wb\")\n",
    "pickle.dump(dict_all,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Experience': {'9 years': 0.03905546559023822, '< 1 year': 0.07956577741866779, '2 years': 0.08887972332002447, '10+ years': 0.37908717695595684, '5 years': 0.06277362885531436, '8 years': 0.049533513864988915, '7 years': 0.05025361204175442, '4 years': 0.059195676255579636, '1 year': 0.06434116651396979, '3 years': 0.07891329409418073, '6 years': 0.04840096508932486}}\n"
     ]
    }
   ],
   "source": [
    "file = open(\"Experience.obj\",'rb')\n",
    "terms = pickle.load(file)\n",
    "file.close()\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 year        57095\n",
       "10+ years    336394\n",
       "2 years       78870\n",
       "3 years       70026\n",
       "4 years       52529\n",
       "5 years       55704\n",
       "6 years       42950\n",
       "7 years       44594\n",
       "8 years       43955\n",
       "9 years       34657\n",
       "< 1 year      70605\n",
       "Name: Experience, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg.Experience.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
